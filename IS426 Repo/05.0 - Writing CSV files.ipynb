{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conservative-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MAC', 'SSID'])\n"
     ]
    }
   ],
   "source": [
    "# Write data to csv using the dictionary writer all at once\n",
    "\n",
    "import csv\n",
    "\n",
    "#list of dictionaries\n",
    "data = [{'MAC': 'e0:91:f5:de:fa:4f', 'SSID': 'NETGEAR-5G'}, \n",
    "        {'MAC': 'e2:91:f5:de:fa:51', 'SSID': 'bonesaw_Guest'}, \n",
    "        {'MAC': 'e0:91:f5:de:fa:50', 'SSID': 'BONESAW_HQ'},\n",
    "        {'MAC': 'e0:91:f5:5e:34:60', 'SSID': 'Happy_Clam'}]\n",
    "\n",
    "keys = data[0].keys()\n",
    "print(keys)\n",
    "f = open('data/wifi_list2.csv', 'w', newline='')\n",
    "dict_writer = csv.DictWriter(f, keys)\n",
    "dict_writer.writeheader()\n",
    "dict_writer.writerows(data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "black-excess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e0:91:f5:de:fa:4f', 'NETGEAR-5G']\n",
      "['e2:91:f5:de:fa:51', 'bonesaw_Guest']\n",
      "['e0:91:f5:de:fa:50', 'BONESAW_HQ']\n",
      "['e0:91:f5:5e:34:60', 'Happy_Clam']\n"
     ]
    }
   ],
   "source": [
    "# Write rows one at a time as lists\n",
    "\n",
    "import csv\n",
    "\n",
    "#clear the file\n",
    "f = open('data/wifi_list3.csv', 'w', newline ='')\n",
    "f.write('')\n",
    "f.close()\n",
    "\n",
    "\n",
    "data = [{'MAC': 'e0:91:f5:de:fa:4f', 'SSID': 'NETGEAR-5G'}, \n",
    "        {'MAC': 'e2:91:f5:de:fa:51', 'SSID': 'bonesaw_Guest'}, \n",
    "        {'MAC': 'e0:91:f5:de:fa:50', 'SSID': 'BONESAW_HQ'},\n",
    "        {'MAC': 'e0:91:f5:5e:34:60', 'SSID': 'Happy_Clam'}]\n",
    "\n",
    "f = open('data/wifi_list3.csv', 'a', newline ='')\n",
    "writer = csv.writer(f)\n",
    "header = ['mac','ssid']\n",
    "writer.writerow(header)\n",
    "for row in data:\n",
    "    to_write = [row['MAC'],row['SSID']] #build our list to save to the file\n",
    "    print(to_write)\n",
    "    writer.writerow(to_write)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "saved-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['storm_1.csv', 'storm_4.csv', 'storm_2.csv', 'storm_3.csv', 'storm_.csv', 'storm_5.csv'])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'storms/storm_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorms/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m dict_writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(f, rows[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;66;03m#keys\u001b[39;00m\n\u001b[1;32m     29\u001b[0m dict_writer\u001b[38;5;241m.\u001b[39mwriteheader()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'storms/storm_1.csv'"
     ]
    }
   ],
   "source": [
    "# Write script which reads data from the file data/storms.csv and \n",
    "#    saves them to 4 csv files organized by storm category.  For example \n",
    "#    storm_1.csv has only storms which are category 1 on the Saffir-Simpson Scale.\n",
    "#  each category file should contain the following fields:\n",
    "#  name,type,year,category,wind,area\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/storms.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "storms_by_cat = {}\n",
    "            \n",
    "for row in data:\n",
    "    cat = row['Category (Saffir-Simpson Scale)']\n",
    "    k = f\"storm_{cat}.csv\" # the key. Makes a new csv file for every single row\n",
    "    if k in storms_by_cat:\n",
    "        storms_by_cat[k].append(row) #checks if this key already exists\n",
    "    else:\n",
    "        storms_by_cat[k] = [row] # if it doesn't it adds it to the list\n",
    "\n",
    "print(storms_by_cat.keys())        \n",
    "    \n",
    "for fn, rows in storms_by_cat.items():\n",
    "    fp = f\"storms/{fn}\"\n",
    "    f = open(fp, 'w', newline='')\n",
    "    dict_writer = csv.DictWriter(f, rows[0].keys) #keys\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(rows)\n",
    "    f.close()\n",
    "\n",
    "            \n",
    "'''           \n",
    "storms {}\n",
    "        storm_1.csv []\n",
    "            0 {}\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "positive-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the same file as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "significant-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurricane Haiyan in 2013: 170 knots\n"
     ]
    }
   ],
   "source": [
    "# Find the year and name of the storm with the highest wind speed\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/storms.csv') as f:\n",
    "    data = [{k: str(v) for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "\n",
    "prev = 0\n",
    "\n",
    "for row in data:\n",
    "    \n",
    "    try:\n",
    "        new = int(row['Wind (knots)'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if new > prev:\n",
    "        prev = new\n",
    "        name = row['Name']\n",
    "        year = row['Year']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "print (f\"Hurricane {name} in {year}: {max} knots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 lists of the count of named storms each month.  \n",
    "#    One list for Atlantic region and \n",
    "#     one for all pacific regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-convergence",
   "metadata": {},
   "source": [
    "To Know:\n",
    "* How to write data structures like lists and dictionaries to csv files\n",
    "* Write filters which can select certain data and save it to a new file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-europe",
   "metadata": {},
   "source": [
    "What can go wrong:\n",
    "* Make sure you only write strings to files or use row writer\n",
    "* debugging blank files\n",
    "* extra lines in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-launch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
